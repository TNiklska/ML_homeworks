{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Секція 1. Логістична регресія з нуля."
      ],
      "metadata": {
        "id": "ha9AUz4jhjny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перетворіть inputs, targets на torch тензори"
      ],
      "metadata": {
        "id": "Ti6CCP_gfdmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення вхідних даних і цілей у тензори\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3c7d43-e909-4ec0-f365-8b177b17a886"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ініціюйте ваги w, b для моделі логістичної регресії"
      ],
      "metadata": {
        "id": "1K9kIYicfqoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e8bb45-edf0-4363-c8f8-8f3b567ed409"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a0194164f70>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(1, 3, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b768c8f-b872-4f88-fadc-30c65bc051e2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "tensor([0.6213], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Напишіть функцію model, яка буде обчислювати функцію гіпотези в логістичній регресії"
      ],
      "metadata": {
        "id": "sZqja2wff2kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаємо модель\n",
        "def model(x, w, b):\n",
        "     return 1 / (1 + torch.exp(-(x @ w.t() + b)))\n"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генеруємо передбачення\n",
        "predicted_probs = model(inputs, w, b)\n",
        "print(predicted_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9jQHggMZKz9",
        "outputId": "7153faae-8798-4889-b87f-d0ba4f4766fd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Порівняємо з таргетами\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th8ACabPZOY_",
        "outputId": "6384f58e-004d-4437-ebec-7782b9f0d35c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Аналіз передбачень:**\n",
        "Як можна бачити, то всі передбачення однакові і відповідають перевачаючому класу в мітках."
      ],
      "metadata": {
        "id": "_OceN-LuklWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Напишіть функцію binary_cross_entropy"
      ],
      "metadata": {
        "id": "LmzQZrgUf9ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n"
      ],
      "metadata": {
        "id": "wSdZZb_Tjbbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "    loss = -(true_labels*torch.log(predicted_probs)+(1-true_labels)*torch.log(1-predicted_probs))\n",
        "    return torch.mean(loss)\n"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(predicted_probs, targets)\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkNyGR90lb-J",
        "outputId": "063df72d-f610-469d-a736-25b1eba8fee0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Зворотнє поширеня помилки"
      ],
      "metadata": {
        "id": "RPtsR0Fs8hol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обчислимо gradients\n",
        "loss.backward()\n"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнти параметру w\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihzdEY4r76b7",
        "outputId": "e4df0a99-cb0c-405b-de23-c00e2d6b3731"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "tensor([[nan, nan, nan]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнти параметру b\n",
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VfM14y87-kS",
        "outputId": "effbc56d-3a49-4493-ca6b-c408f79ee0f0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6213], requires_grad=True)\n",
            "tensor([nan])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Аналіз помилок:**\n",
        "Оскільки середня помилка nan, то думаю це вплинуло градієнт параметрів."
      ],
      "metadata": {
        "id": "KrPBRC-HlAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генеруємо передбачення\n",
        "predicted_probs = model(inputs, w, b)\n",
        "print(predicted_probs)\n",
        "loss = binary_cross_entropy(predicted_probs, targets)\n",
        "# Обчислимо gradients\n",
        "loss.backward()\n",
        "print(f'loss:{loss}')"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b908d-98f0-4e9b-8ead-9c3f39b1f75e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<MulBackward0>)\n",
            "loss:0.6829456686973572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнти параметру w\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRf4-ul2-ZUa",
        "outputId": "09bb300b-1289-43e6-8da1-23e8ba81423b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.6135e-04, 2.6692e-04, 6.1677e-05]], requires_grad=True)\n",
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнти параметру b\n",
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WYvpyLC-j9A",
        "outputId": "76ce2bdb-d0fd-44ee-8ef0-7ed5e78b9ff3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0006], requires_grad=True)\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Алгоритм градієнтного спуску"
      ],
      "metadata": {
        "id": "8na2TDjm_JLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Градієнтний спуск протягом 1000 епох\n",
        "for i in range(1000):\n",
        "    predicts = model(inputs, w, b)\n",
        "    loss = binary_cross_entropy(predicts, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "mObHPyE06qsO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicts = model(inputs, w, b)\n",
        "loss = binary_cross_entropy(predicts, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsKI0wwcAYGc",
        "outputId": "5d3c3684-4c84-4626-d7c6-6c8f9a29c162"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3357, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGvq5D_PpDGf",
        "outputId": "e40721fd-7678-4330-a239-ac55b1597fb1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5777],\n",
            "        [0.6685],\n",
            "        [0.9113],\n",
            "        [0.1616],\n",
            "        [0.8653]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdH3LMNYpJ66",
        "outputId": "753b7ac5-61c1-4523-8f89-831094fb681b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки:**\n",
        " За результатами виконання градієнтного спуску втрати суттєво зменшились. Помилка збереглась в першому рядку."
      ],
      "metadata": {
        "id": "Xn0dS1FvAugv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Секція 2. Створення лог регресії з використанням функціоналу torch.nn."
      ],
      "metadata": {
        "id": "bH3benB9CoHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Створення датасету TensorDataset"
      ],
      "metadata": {
        "id": "xD--9MCED7WS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпорт tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "dStIUTUmDPFW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_l = torch.from_numpy(inputs)\n",
        "targets_l = torch.from_numpy(targets)\n",
        "\n",
        "train_ds = TensorDataset(inputs_l, targets_l)\n",
        "train_ds[0:3]"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deae968e-c437-43d5-f6de-771fb8b74d29"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loader з класом DataLoader"
      ],
      "metadata": {
        "id": "VzCn0X1vEkh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаємо data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#виведення першого елемента\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOtb9hk1qUkj",
        "outputId": "af451b69-8855-45cd-f5e8-6b84afb6b88c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [102.,  43.,  37.],\n",
              "         [ 69.,  96.,  70.],\n",
              "         [102.,  43.,  37.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Створення екземпляра класу LogReg в змінній model"
      ],
      "metadata": {
        "id": "5_NWT_53EtES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xLXdXZO2Mi8j"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogReg(nn.Module):\n",
        "    # Initialize the layers\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(3, 10)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(10, 5)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(5, 1)\n",
        "\n",
        "\n",
        "\n",
        "    # Perform the computation\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.linear3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogReg()"
      ],
      "metadata": {
        "id": "4bm67bChIdPN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задання оптимізатора, функції втрат та навчання моделі"
      ],
      "metadata": {
        "id": "9FzGuDssZXVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#оптимізатор Stockastic Gradient Descent\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визначення loss функцію втрат binary_cross_entropy\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "Q3fQmLPiW8En"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##втрати для поточних передбачень і міток\n",
        "loss = loss_fn(model(inputs_l), targets_l)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6yP55Q7XX5Q",
        "outputId": "e2e4477f-a339-44df-9aaa-2796fd66e5e3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6729, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаэмо функцію для навчання моделі\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            # Створення передбачень\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконання градієнтного спуску\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "    print('Training loss: ', loss_fn(model(inputs_l), targets_l))"
      ],
      "metadata": {
        "id": "cJsAqGRb1vV3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE12fS5Z1zuM",
        "outputId": "2ec64062-8b3a-48cd-b287-4cae806d2944"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  tensor(0.2528, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#виведення передбачень\n",
        "print(model(inputs_l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG_yzwQeWkhk",
        "outputId": "cfa97676-0c41-4257-a715-5b3e5cb8a1c7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5127],\n",
            "        [0.5984],\n",
            "        [0.9961],\n",
            "        [0.0065],\n",
            "        [0.9790],\n",
            "        [0.5127],\n",
            "        [0.5984],\n",
            "        [0.9961],\n",
            "        [0.0065],\n",
            "        [0.9790],\n",
            "        [0.5127],\n",
            "        [0.5984],\n",
            "        [0.9961],\n",
            "        [0.0065],\n",
            "        [0.9790]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#виведення міток\n",
        "print(targets_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3rz5_r6XuHr",
        "outputId": "a5686620-1adf-4181-dbd9-710d5a9dab37"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки:**\n",
        "Навчання було на 100 епохах і результат моделі значно покращився: з 0.6729 до 0.2528.\n"
      ],
      "metadata": {
        "id": "HdaZrDJHYqfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Тренування моделі на 1000 епох з відстеженням loss"
      ],
      "metadata": {
        "id": "yB5S1cjWZxaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція fit для відстеження втрат\n",
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Ініціалізуємо акумулятор для втрат\n",
        "        total_loss = 0\n",
        "\n",
        "        for xb, yb in train_dl:\n",
        "            # Генеруємо передбачення\n",
        "            pred = model(xb)\n",
        "\n",
        "            # Обчислюємо втрати\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            # Виконуємо градієнтний спуск\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # Накопичуємо втрати\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Обчислюємо середні втрати для епохи\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Виводимо підсумок епохи\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses"
      ],
      "metadata": {
        "id": "C-qSJlLpZHlZ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = fit_return_loss(1000, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "id": "cEHQH9qE626k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ea5190-b133-4e13-af6f-0be5e8161578"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Loss: 0.2565\n",
            "Epoch [20/1000], Loss: 0.2534\n",
            "Epoch [30/1000], Loss: 0.2690\n",
            "Epoch [40/1000], Loss: 0.2780\n",
            "Epoch [50/1000], Loss: 0.2658\n",
            "Epoch [60/1000], Loss: 0.2438\n",
            "Epoch [70/1000], Loss: 0.2525\n",
            "Epoch [80/1000], Loss: 0.2520\n",
            "Epoch [90/1000], Loss: 0.2499\n",
            "Epoch [100/1000], Loss: 0.2351\n",
            "Epoch [110/1000], Loss: 0.2323\n",
            "Epoch [120/1000], Loss: 0.2416\n",
            "Epoch [130/1000], Loss: 0.2265\n",
            "Epoch [140/1000], Loss: 0.2233\n",
            "Epoch [150/1000], Loss: 0.2147\n",
            "Epoch [160/1000], Loss: 0.2193\n",
            "Epoch [170/1000], Loss: 0.2613\n",
            "Epoch [180/1000], Loss: 0.2138\n",
            "Epoch [190/1000], Loss: 0.2111\n",
            "Epoch [200/1000], Loss: 0.2068\n",
            "Epoch [210/1000], Loss: 0.2230\n",
            "Epoch [220/1000], Loss: 0.2015\n",
            "Epoch [230/1000], Loss: 0.1988\n",
            "Epoch [240/1000], Loss: 0.2130\n",
            "Epoch [250/1000], Loss: 0.2167\n",
            "Epoch [260/1000], Loss: 0.1880\n",
            "Epoch [270/1000], Loss: 0.2031\n",
            "Epoch [280/1000], Loss: 0.1933\n",
            "Epoch [290/1000], Loss: 0.1726\n",
            "Epoch [300/1000], Loss: 0.1788\n",
            "Epoch [310/1000], Loss: 0.1857\n",
            "Epoch [320/1000], Loss: 0.1712\n",
            "Epoch [330/1000], Loss: 0.1785\n",
            "Epoch [340/1000], Loss: 0.1635\n",
            "Epoch [350/1000], Loss: 0.1530\n",
            "Epoch [360/1000], Loss: 0.1706\n",
            "Epoch [370/1000], Loss: 0.1675\n",
            "Epoch [380/1000], Loss: 0.2124\n",
            "Epoch [390/1000], Loss: 0.1848\n",
            "Epoch [400/1000], Loss: 0.1399\n",
            "Epoch [410/1000], Loss: 0.1396\n",
            "Epoch [420/1000], Loss: 0.1301\n",
            "Epoch [430/1000], Loss: 0.1266\n",
            "Epoch [440/1000], Loss: 0.1248\n",
            "Epoch [450/1000], Loss: 0.1354\n",
            "Epoch [460/1000], Loss: 0.1226\n",
            "Epoch [470/1000], Loss: 0.1142\n",
            "Epoch [480/1000], Loss: 0.1347\n",
            "Epoch [490/1000], Loss: 0.1334\n",
            "Epoch [500/1000], Loss: 0.1188\n",
            "Epoch [510/1000], Loss: 0.1503\n",
            "Epoch [520/1000], Loss: 0.1016\n",
            "Epoch [530/1000], Loss: 0.1020\n",
            "Epoch [540/1000], Loss: 0.1003\n",
            "Epoch [550/1000], Loss: 0.0963\n",
            "Epoch [560/1000], Loss: 0.0947\n",
            "Epoch [570/1000], Loss: 0.0959\n",
            "Epoch [580/1000], Loss: 0.1002\n",
            "Epoch [590/1000], Loss: 0.0905\n",
            "Epoch [600/1000], Loss: 0.0826\n",
            "Epoch [610/1000], Loss: 0.0797\n",
            "Epoch [620/1000], Loss: 0.0763\n",
            "Epoch [630/1000], Loss: 0.0784\n",
            "Epoch [640/1000], Loss: 0.0735\n",
            "Epoch [650/1000], Loss: 0.0769\n",
            "Epoch [660/1000], Loss: 0.0671\n",
            "Epoch [670/1000], Loss: 0.0639\n",
            "Epoch [680/1000], Loss: 0.0739\n",
            "Epoch [690/1000], Loss: 0.0633\n",
            "Epoch [700/1000], Loss: 0.0584\n",
            "Epoch [710/1000], Loss: 0.0582\n",
            "Epoch [720/1000], Loss: 0.0560\n",
            "Epoch [730/1000], Loss: 0.0549\n",
            "Epoch [740/1000], Loss: 0.0656\n",
            "Epoch [750/1000], Loss: 0.0513\n",
            "Epoch [760/1000], Loss: 0.0681\n",
            "Epoch [770/1000], Loss: 0.0521\n",
            "Epoch [780/1000], Loss: 0.0463\n",
            "Epoch [790/1000], Loss: 0.0460\n",
            "Epoch [800/1000], Loss: 0.0445\n",
            "Epoch [810/1000], Loss: 0.0427\n",
            "Epoch [820/1000], Loss: 0.0421\n",
            "Epoch [830/1000], Loss: 0.0405\n",
            "Epoch [840/1000], Loss: 0.0383\n",
            "Epoch [850/1000], Loss: 0.0393\n",
            "Epoch [860/1000], Loss: 0.0480\n",
            "Epoch [870/1000], Loss: 0.0352\n",
            "Epoch [880/1000], Loss: 0.0369\n",
            "Epoch [890/1000], Loss: 0.0350\n",
            "Epoch [900/1000], Loss: 0.0360\n",
            "Epoch [910/1000], Loss: 0.0362\n",
            "Epoch [920/1000], Loss: 0.0361\n",
            "Epoch [930/1000], Loss: 0.0301\n",
            "Epoch [940/1000], Loss: 0.0319\n",
            "Epoch [950/1000], Loss: 0.0350\n",
            "Epoch [960/1000], Loss: 0.0290\n",
            "Epoch [970/1000], Loss: 0.0363\n",
            "Epoch [980/1000], Loss: 0.0281\n",
            "Epoch [990/1000], Loss: 0.0299\n",
            "Epoch [1000/1000], Loss: 0.0261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ciP2F6ZrZcKp",
        "outputId": "b2c19475-1fad-4ad9-c626-3794a087f157"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictl = model(inputs_l)\n",
        "predictl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pJH2H6bo79",
        "outputId": "fe5b6316-cfbd-4033-b03c-9395e34720fd"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.3301e-02],\n",
              "        [9.3983e-01],\n",
              "        [9.9998e-01],\n",
              "        [1.6100e-11],\n",
              "        [9.9979e-01],\n",
              "        [6.3301e-02],\n",
              "        [9.3983e-01],\n",
              "        [9.9998e-01],\n",
              "        [1.6100e-11],\n",
              "        [9.9979e-01],\n",
              "        [6.3301e-02],\n",
              "        [9.3983e-01],\n",
              "        [9.9998e-01],\n",
              "        [1.6100e-11],\n",
              "        [9.9979e-01]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr3kelWz3d4f",
        "outputId": "a79321fc-600b-4741-e25f-06a111f7de73"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    }
  ]
}